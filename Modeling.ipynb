{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "Ir4BN2vSqf6a",
        "outputId": "7dad6752-8cac-4a17-b942-34cbd71971ad"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'signature dishes'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'signature dishes'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-77ca5374c5b5>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cuisine'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" \"\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'price_for_two'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" \"\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'signature dishes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'signature dishes'"
          ]
        }
      ],
      "source": [
        "# import pandas as pd\n",
        "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# # 1. Load the dataset\n",
        "# data = pd.read_csv(\"final.csv\")\n",
        "\n",
        "# # 2. Check the columns (modify as needed based on your dataset)\n",
        "# # print(data.head())\n",
        "\n",
        "# # Example columns: ['name', 'cuisine', 'price_for_two', 'signature_dish', 'location', 'rating']\n",
        "\n",
        "# # 3. Create a 'profile' combining relevant features including the signature dish\n",
        "# data['profile'] = (\n",
        "#     data['cuisine'].astype(str) + \" \" +\n",
        "#     data['price_for_two'].astype(str) + \" \" +\n",
        "#     data['signature dish'].fillna(\"\").astype(str)\n",
        "# )\n",
        "\n",
        "# # 4. Vectorize the profiles using TF-IDF\n",
        "# vectorizer = TfidfVectorizer(stop_words='english')\n",
        "# tfidf_matrix = vectorizer.fit_transform(data['profile'])\n",
        "\n",
        "# # 5. Define a function to get restaurant recommendations based on user input\n",
        "# def recommend_restaurants(liked_restaurant, cuisine, price_for_two, top_n=5):\n",
        "#     # Filter the dataset based on input cuisine and price range\n",
        "#     filtered_data = data[\n",
        "#         (data['cuisine'].str.contains(cuisine, case=False, na=False)) &\n",
        "#         (data['price_for_two'] <= price_for_two)\n",
        "#     ]\n",
        "\n",
        "#     if filtered_data.empty:\n",
        "#         return \"No restaurants found matching your criteria.\"\n",
        "\n",
        "#     # Find the index of the liked restaurant\n",
        "#     liked_index = data[data['name'].str.contains(liked_restaurant, case=False, na=False)].index\n",
        "\n",
        "#     if liked_index.empty:\n",
        "#         return \"The liked restaurant is not found in the dataset.\"\n",
        "\n",
        "#     liked_index = liked_index[0]\n",
        "\n",
        "#     # Calculate similarity between the liked restaurant and others\n",
        "#     similarity_scores = cosine_similarity(tfidf_matrix[liked_index], tfidf_matrix[filtered_data.index])\n",
        "\n",
        "#     # Get top N recommendations (excluding the liked restaurant itself)\n",
        "#     filtered_data['similarity'] = similarity_scores.flatten()\n",
        "#     recommendations = (\n",
        "#         filtered_data.sort_values(by='similarity', ascending=False)\n",
        "#         .head(top_n + 1)  # +1 to include the liked restaurant for filtering\n",
        "#     )\n",
        "\n",
        "#     # Exclude the liked restaurant from the final recommendations\n",
        "#     recommendations = recommendations[recommendations['names'].str.lower() != liked_restaurant.lower()]\n",
        "\n",
        "#     # Return the top N recommendations\n",
        "#     return recommendations[['names', 'cuisine', 'signature dishes', 'price_for_two', 'ratings', 'location']]\n",
        "\n",
        "# # 6. Example: Get user input and recommend restaurants\n",
        "# liked_restaurant = input(\"Enter a restaurant you liked: \")\n",
        "# cuisine = input(\"Enter preferred cuisine: \")\n",
        "# price_for_two = int(input(\"Enter your budget for two people: \"))\n",
        "\n",
        "# # 7. Get recommendations\n",
        "# result = recommend_restaurants(liked_restaurant, cuisine, price_for_two)[:5]\n",
        "# result = pd.DataFrame(result)\n",
        "# # result = result.to_dict('records')\n",
        "# print(result.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# 1. Load the dataset\n",
        "data = pd.read_csv(\"final.csv\")\n",
        "\n",
        "# 2. Check the columns (modify as needed based on your dataset)\n",
        "# print(data.head())\n",
        "\n",
        "# Example columns: ['name', 'cuisine', 'price_for_two', 'signature_dish', 'location', 'rating']\n",
        "\n",
        "# 3. Create a 'profile' combining relevant features including signature dish\n",
        "data['profile'] = (\n",
        "    data['cuisine'].astype(str) + \" \" +\n",
        "    data['price_for_two'].astype(str) + \" \" +\n",
        "    data['signature dish'].fillna(\"\").astype(str)\n",
        ")\n",
        "\n",
        "# 4. Vectorize the profiles using TF-IDF\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = vectorizer.fit_transform(data['profile'])\n",
        "\n",
        "# 5. Define a function to recommend restaurants with rating-based weighting\n",
        "def recommend_restaurants(liked_restaurant, cuisine, price_for_two, top_n=5):\n",
        "    # Filter the dataset based on input cuisine and price range\n",
        "    filtered_data = data[\n",
        "        (data['cuisine'].str.contains(cuisine, case=False, na=False)) &\n",
        "        (data['price_for_two'] <= price_for_two)\n",
        "    ]\n",
        "\n",
        "    if filtered_data.empty:\n",
        "        return \"No restaurants found matching your criteria.\"\n",
        "\n",
        "    # Find the index of the liked restaurant\n",
        "    liked_index = data[data['name'].str.contains(liked_restaurant, case=False, na=False)].index\n",
        "\n",
        "    if liked_index.empty:\n",
        "        return \"The liked restaurant is not found in the dataset.\"\n",
        "\n",
        "    liked_index = liked_index[0]\n",
        "\n",
        "    # Calculate similarity between the liked restaurant and others\n",
        "    similarity_scores = cosine_similarity(tfidf_matrix[liked_index], tfidf_matrix[filtered_data.index]).flatten()\n",
        "\n",
        "    # Incorporate ratings: Multiply similarity by normalized rating (rating / max_rating)\n",
        "    max_rating = data['rating'].max()\n",
        "    filtered_data['weighted_score'] = similarity_scores * (filtered_data['rating'] / max_rating)\n",
        "\n",
        "    # Sort by the weighted score\n",
        "    recommendations = filtered_data.sort_values(by='weighted_score', ascending=False).head(top_n)\n",
        "\n",
        "    # Return top N recommendations\n",
        "    return recommendations[['name', 'cuisine', 'signature dish', 'price_for_two', 'rating', 'location']]\n",
        "\n",
        "# 6. Example: Get user input and recommend restaurants\n",
        "liked_restaurant = input(\"Enter a restaurant you liked: \")\n",
        "cuisine = input(\"Enter preferred cuisine: \")\n",
        "price_for_two = int(input(\"Enter your budget for two people: \"))\n",
        "\n",
        "# 7. Get recommendations\n",
        "result = recommend_restaurants(liked_restaurant, cuisine, price_for_two)\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfBb-Bf8XzpR",
        "outputId": "7809e5b3-019e-4547-f845-16df233ea37b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a restaurant you liked: nannayya\n",
            "Enter preferred cuisine: south indian\n",
            "Enter your budget for two people: 300\n",
            "                    name                                         cuisine  \\\n",
            "1732   Grand Local Dhaba             North Indian, Biryani, South Indian   \n",
            "1486    Dosth Food Court             North Indian, Chinese, South Indian   \n",
            "989      Eat Chat & More             North Indian, South Indian, Chinese   \n",
            "1685    Aahaa Food Court  South Indian, Chinese, North Indian, Beverages   \n",
            "2345  Sampurna's Kitchen                      North Indian, South Indian   \n",
            "\n",
            "     signature dish  price_for_two  rating                 location  \n",
            "1732            NaN          300.0     4.0  Dilsukhnagar, Hyderabad  \n",
            "1486            NaN          300.0     3.9  Dilsukhnagar, Hyderabad  \n",
            "989             NaN          300.0     3.8    Kukatpally, Hyderabad  \n",
            "1685            NaN          200.0     3.9  Saroor Nagar, Hyderabad  \n",
            "2345            NaN          300.0     3.2      Madhapur, Hyderabad  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-2b37da0904e5>:48: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  filtered_data['weighted_score'] = similarity_scores * (filtered_data['rating'] / max_rating)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# # Load dataset\n",
        "# df = pd.read_csv(\"final.csv\")\n",
        "\n",
        "# # Step 1: Vectorize and Precompute Similarity Matrices\n",
        "# def compute_similarity_matrix(column):\n",
        "#     vectorizer = TfidfVectorizer(stop_words='english')\n",
        "#     matrix = vectorizer.fit_transform(df[column].fillna(''))\n",
        "#     return cosine_similarity(matrix)\n",
        "\n",
        "# cuisine_sim_matrix = compute_similarity_matrix('cuisine')\n",
        "# dish_sim_matrix = compute_similarity_matrix('signature dish')\n",
        "# location_sim_matrix = compute_similarity_matrix('location')\n",
        "\n",
        "# # Step 2: Save matrices (optional) to avoid recomputing every time\n",
        "# # np.save('cuisine_sim_matrix.npy', cuisine_sim_matrix)\n",
        "# # np.save('dish_sim_matrix.npy', dish_sim_matrix)\n",
        "# # np.save('location_sim_matrix.npy', location_sim_matrix)\n",
        "\n",
        "# # Step 3: Function to Recommend Restaurants Using Precomputed Similarity\n",
        "# def recommend_restaurants_with_precomputed(\n",
        "#     prev_restaurant=None, min_budget=None, max_budget=None, user_location=None, top_n=5\n",
        "# ):\n",
        "#     filtered_df = df\n",
        "\n",
        "#     # Filter by budget if provided\n",
        "#     if min_budget is not None and max_budget is not None:\n",
        "#         filtered_df = filtered_df[\n",
        "#             (filtered_df['price_for_two'] >= min_budget) &\n",
        "#             (filtered_df['price_for_two'] <= max_budget)\n",
        "#         ]\n",
        "\n",
        "#     idx = df.index[0]\n",
        "#     if prev_restaurant:\n",
        "#         try:\n",
        "#             idx = df[df['name'].str.lower() == prev_restaurant.lower()].index[0]\n",
        "#         except IndexError:\n",
        "#             print(\"Previous restaurant not found, using default.\")\n",
        "\n",
        "#     # Use Precomputed Similarity Scores\n",
        "#     cuisine_sim = cuisine_sim_matrix[idx]\n",
        "#     dish_sim = dish_sim_matrix[idx]\n",
        "\n",
        "#     if user_location:\n",
        "#         location_sim = location_sim_matrix[idx]\n",
        "#     else:\n",
        "#         location_sim = np.zeros(len(df))\n",
        "\n",
        "#     # Calculate Final Score\n",
        "#     final_scores = (\n",
        "#         0.3 * cuisine_sim +\n",
        "#         0.3 * dish_sim +\n",
        "#         0.2 * location_sim\n",
        "#     )\n",
        "\n",
        "#     # Get Top Recommendations\n",
        "#     top_indices = np.argsort(final_scores)[::-1][:top_n]\n",
        "#     recommendations = df.iloc[top_indices][\n",
        "#         ['name', 'cuisine', 'location', 'price_for_two', 'rating']\n",
        "#     ]\n",
        "#     return recommendations\n",
        "\n",
        "# # Example Usage\n",
        "# city_rec = recommend_restaurants_with_precomputed(\n",
        "#     prev_restaurant=\"osaka\",\n",
        "#     user_location=\"\", top_n=5\n",
        "# )\n",
        "\n",
        "# print(\"Top Recommended Restaurants:\")\n",
        "# print(city_rec)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1Iu1nqFr1qp",
        "outputId": "06066263-835e-4c8c-fbaf-2e1bed4d06b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top Recommended Restaurants:\n",
            "                                  name  \\\n",
            "401                              Osaka   \n",
            "10      Sakura - A Far Eastern Kitchen   \n",
            "1426                      China Bistro   \n",
            "979                            You Mee   \n",
            "137   Ha - Luo Oriental Cafe & Kitchen   \n",
            "\n",
            "                                                cuisine  \\\n",
            "401                Asian, Japanese, Sushi, Korean, Thai   \n",
            "10    Japanese, Asian, Thai, Sushi, Korean, Chinese,...   \n",
            "1426  Chinese, Asian, Sushi, Japanese, Korean, Thai,...   \n",
            "979   Asian, Japanese, Sushi, Chinese, Thai, Dessert...   \n",
            "137   Oriental, Chinese, Japanese, Sichuan, Desserts...   \n",
            "\n",
            "                      location  price_for_two  rating  \n",
            "401   Jubilee Hills, Hyderabad         1000.0     4.2  \n",
            "10    Jubilee Hills, Hyderabad         1600.0     4.4  \n",
            "1426  Jubilee Hills, Hyderabad         1800.0     4.6  \n",
            "979      Kukatpally, Hyderabad         2000.0     4.4  \n",
            "137     Hitech City, Hyderabad         1400.0     4.5  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cuisine_sim_matrix.shape\n"
      ],
      "metadata": {
        "id": "xI6z29c4vfJG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93bbcc17-263a-498a-9a13-e19bba45b0a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2420, 2420)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# import pandas as pd\n",
        "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# from sklearn.metrics.pairwise import cosine_similarity\n",
        "# import numpy as np\n",
        "\n",
        "# # Load dataset\n",
        "# df = pd.read_csv(\"final.csv\")\n",
        "\n",
        "# # Step 1: Vectorize and Precompute Similarity Matrices\n",
        "# def compute_similarity_matrix(column):\n",
        "#     vectorizer = TfidfVectorizer(stop_words='english')\n",
        "#     matrix = vectorizer.fit_transform(df[column].fillna(''))\n",
        "#     return cosine_similarity(matrix)\n",
        "\n",
        "# cuisine_sim_matrix = compute_similarity_matrix('cuisine')\n",
        "# dish_sim_matrix = compute_similarity_matrix('signature dish')\n",
        "\n",
        "# # Step 2: Function to Recommend Restaurants Using Precomputed Similarity\n",
        "# def recommend_restaurants_with_precomputed(\n",
        "#     liked_restaurant, cuisine, budget_for_two, top_n=5\n",
        "# ):\n",
        "#     filtered_df = df\n",
        "\n",
        "#     # Filter by cuisine and budget\n",
        "#     filtered_df = filtered_df[\n",
        "#         (filtered_df['cuisine'].str.contains(cuisine, case=False, na=False)) &\n",
        "#         (filtered_df['price_for_two'] <= budget_for_two)\n",
        "#     ]\n",
        "\n",
        "#     if filtered_df.empty:\n",
        "#         return \"No restaurants found matching your criteria.\"\n",
        "\n",
        "#     idx = df.index[0]\n",
        "#     if liked_restaurant:\n",
        "#         try:\n",
        "#             idx = df[df['name'].str.lower() == liked_restaurant.lower()].index[0]\n",
        "#         except IndexError:\n",
        "#             print(\"Liked restaurant not found, using default.\")\n",
        "\n",
        "#     # Use Precomputed Similarity Scores\n",
        "#     cuisine_sim = cuisine_sim_matrix[idx]\n",
        "#     dish_sim = dish_sim_matrix[idx]\n",
        "\n",
        "#     # Calculate Final Score\n",
        "#     final_scores = (\n",
        "#         0.6 * cuisine_sim +\n",
        "#         0.4 * dish_sim\n",
        "#     )\n",
        "\n",
        "#     # Get Top Recommendations\n",
        "#     top_indices = np.argsort(final_scores)[::-1][:top_n]\n",
        "#     recommendations = filtered_df.iloc[top_indices][\n",
        "#         ['name', 'cuisine', 'signature dish', 'price_for_two', 'rating', 'location']\n",
        "#     ]\n",
        "#     return recommendations\n",
        "\n",
        "# # Example Usage\n",
        "# liked_restaurant = input(\"Enter a restaurant you liked (or leave blank if none): \")\n",
        "# cuisine = input(\"Enter preferred cuisine (e.g., Italian, Indian, etc.): \")\n",
        "# budget_for_two = int(input(\"Enter your budget for two people: \"))\n",
        "\n",
        "# recommendations = recommend_restaurants_with_precomputed(\n",
        "#     liked_restaurant, cuisine, budget_for_two\n",
        "# )\n",
        "\n",
        "# if isinstance(recommendations, str):\n",
        "#     print(recommendations)\n",
        "# else:\n",
        "#     print(\"Top Recommended Restaurants:\")\n",
        "#     print(recommendations)\n",
        "\n"
      ],
      "metadata": {
        "id": "EeqaW3TyZs4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "outputId": "3885c8f1-1b43-4954-d744-7ca173ca13b7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter a restaurant you liked (or leave blank if none): osaka\n",
            "Enter preferred cuisine (e.g., Italian, Indian, etc.): indian\n",
            "Enter your budget for two people: 5000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "positional indexers are out-of-bounds",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_list_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1713\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1714\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take_with_is_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1715\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_take_with_is_copy\u001b[0;34m(self, indices, axis)\u001b[0m\n\u001b[1;32m   4152\u001b[0m         \"\"\"\n\u001b[0;32m-> 4153\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4154\u001b[0m         \u001b[0;31m# Maybe set copy if we didn't actually change the index.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indices, axis, **kwargs)\u001b[0m\n\u001b[1;32m   4132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4133\u001b[0;31m         new_data = self._mgr.take(\n\u001b[0m\u001b[1;32m   4134\u001b[0m             \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indexer, axis, verify)\u001b[0m\n\u001b[1;32m    890\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_convert_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexers/utils.py\u001b[0m in \u001b[0;36mmaybe_convert_indices\u001b[0;34m(indices, n, verify)\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"indices are out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: indices are out-of-bounds",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-aed90a9bb9f8>\u001b[0m in \u001b[0;36m<cell line: 64>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0mbudget_for_two\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter your budget for two people: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m recommendations = recommend_restaurants_with_precomputed(\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0mliked_restaurant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuisine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbudget_for_two\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m )\n",
            "\u001b[0;32m<ipython-input-6-aed90a9bb9f8>\u001b[0m in \u001b[0;36mrecommend_restaurants_with_precomputed\u001b[0;34m(liked_restaurant, cuisine, budget_for_two, top_n)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;31m# Get Top Recommendations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mtop_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtop_n\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     recommendations = filtered_df.iloc[top_indices][\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cuisine'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'signature dish'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'price_for_two'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rating'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'location'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     ]\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1189\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_deprecated_callable_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaybe_callable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1741\u001b[0m         \u001b[0;31m# a list of integers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1742\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_list_like_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1743\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_list_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m         \u001b[0;31m# a single integer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_list_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1715\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1716\u001b[0m             \u001b[0;31m# re-raise with different error message, e.g. test_getitem_ndarray_3d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1717\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"positional indexers are out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1719\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAxisInt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: positional indexers are out-of-bounds"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GUSYaz0yt0d9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}